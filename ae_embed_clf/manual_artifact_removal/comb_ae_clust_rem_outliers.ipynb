{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8f58faae-865f-4b8e-a0af-4dce7a75586e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import json\n",
    "from PIL import Image\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from define_dataset import define_dataset\n",
    "from define_ext_dataset import define_ext_dataset\n",
    "from remove_outliers_clustering import find_and_remove_outliers_clustering, remove_outliers_clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f90369d-c8d1-4530-97c5-198fa709a0e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Cluster labels subdivision by slide"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cbff8f6d-6fac-4939-9ea7-003cc3516211",
   "metadata": {},
   "outputs": [],
   "source": [
    "def subdivide_clusters_by_slide(n_clusters, labels, percentile, dataset='comb_tr'):\n",
    "    # Labels are still ordered by slide, ie the first 25000 tiles are from the first slide, tile 25001\n",
    "    # to 70000 is from the second slide and so on\n",
    "    \n",
    "    if dataset=='comb_val':\n",
    "        num_tiles_dict = num_tiles_dict_comb_val\n",
    "    elif dataset=='comb_ts':\n",
    "        num_tiles_dict = num_tiles_dict_comb_ts\n",
    "    else:\n",
    "        num_tiles_dict = num_tiles_dict_comb_tr\n",
    "\n",
    "    slide_cluster_pth = \"./clustering/comb_ae/slide_clusters_rem_outliers/kmeans{}_out_perc{}\".format(n_clusters, percentile)\n",
    "    if not os.path.exists(slide_cluster_pth):\n",
    "        os.makedirs(slide_cluster_pth)\n",
    "    \n",
    "    # Count tile labels for each slide and save them in same slide folder\n",
    "    start = 0\n",
    "    end = 0\n",
    "    for slide_name in num_tiles_dict:\n",
    "        slide_num_tiles = num_tiles_dict[slide_name]\n",
    "        end += slide_num_tiles\n",
    "        slide_labels = labels[start:end]\n",
    "        start += slide_num_tiles\n",
    "        np.save(os.path.join(slide_cluster_pth, slide_name+\".npy\"), slide_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609e5cdf-b293-4dad-bb44-9c34dbeccc0b",
   "metadata": {},
   "source": [
    "# Import num tiles dicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a0f80af7-74cd-4481-958d-2c30e6cb3563",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dicts with number of tiles for each slide\n",
    "tiles_num_dict_path = './data/num_tiles_dict_comb_tr.json'\n",
    "with open(tiles_num_dict_path) as json_file:\n",
    "    num_tiles_dict_comb_tr = json.load(json_file)\n",
    "    \n",
    "tiles_num_dict_path = './data/num_tiles_dict_comb_val.json'\n",
    "with open(tiles_num_dict_path) as json_file:\n",
    "    num_tiles_dict_comb_val = json.load(json_file)\n",
    "\n",
    "tiles_num_dict_path = './data/num_tiles_dict_comb_ts.json'\n",
    "with open(tiles_num_dict_path) as json_file:\n",
    "    num_tiles_dict_comb_ts = json.load(json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cd9db56a-0b6c-42e8-b7b0-a07a270568f5",
   "metadata": {},
   "outputs": [],
   "source": [
    " def get_tile(index, dataset='tr'):\n",
    "    tiles_path='../WSI/tiles/'\n",
    "    curr_tiles_sum = 0\n",
    "    \n",
    "    if dataset=='ts':\n",
    "        num_tiles_dict = num_tiles_dict_ts\n",
    "    elif dataset=='ext':\n",
    "        num_tiles_dict = num_tiles_dict_ext\n",
    "    else:\n",
    "        num_tiles_dict = num_tiles_dict_tr\n",
    "\n",
    "    for slide_name in num_tiles_dict:\n",
    "        if index < curr_tiles_sum + num_tiles_dict[slide_name]:\n",
    "            selected_slide_name = slide_name\n",
    "            break\n",
    "        curr_tiles_sum += num_tiles_dict[slide_name]\n",
    "\n",
    "    tile_idx = index - curr_tiles_sum\n",
    "\n",
    "    tile_path = os.path.join(tiles_path, selected_slide_name, str(tile_idx) + '.jpg')\n",
    "\n",
    "    img = Image.open(tile_path)\n",
    "\n",
    "\n",
    "    return img, selected_slide_name"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14172b54-20da-4cb8-a125-0559c1e88efa",
   "metadata": {},
   "source": [
    "# Import tile embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bd9fd39e-a982-46ae-8754-3cbb0faee831",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 20\n",
    "save_model_path = './ae_models/comb_ae/'\n",
    "\n",
    "embed_path_comb_tr = os.path.join(save_model_path, 'z_ae_test_epoch{}.npy'.format(epoch))\n",
    "embed_tiles_comb_tr = np.load(embed_path_comb_tr)\n",
    "\n",
    "embed_path_comb_val = os.path.join(save_model_path, 'z_ae_internal_test_epoch{}.npy'.format(epoch))\n",
    "embed_tiles_comb_val = np.load(embed_path_comb_val)\n",
    "\n",
    "embed_path_comb_ts = os.path.join(save_model_path, 'z_ae_ext_test_epoch{}.npy'.format(epoch))\n",
    "embed_tiles_comb_ts = np.load(embed_path_comb_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a4018c2-b72d-4079-ab6a-125568141c92",
   "metadata": {},
   "source": [
    "# Remove Outliers from clustering and find max in Tr set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5d599ee2-54d8-472e-8772-d5ea84170794",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_arr = [32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "592f5d95-8859-45b7-a89c-0ce6991d3dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_arr = [75, 80, 85, 90]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31d9e170-04e8-4831-9b8e-0c4db89d48e2",
   "metadata": {},
   "source": [
    "Remove from each cluster the tiles with distance from centroid > selceted percentile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dfdbaaf9-9641-4455-a902-aec5248fae12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished 32 clusters, percentile 75\n",
      "Finished 32 clusters, percentile 80\n",
      "Finished 32 clusters, percentile 85\n",
      "Finished 32 clusters, percentile 90\n",
      "Finished 64 clusters, percentile 75\n",
      "Finished 64 clusters, percentile 80\n",
      "Finished 64 clusters, percentile 85\n",
      "Finished 64 clusters, percentile 90\n",
      "Finished 128 clusters, percentile 75\n",
      "Finished 128 clusters, percentile 80\n",
      "Finished 128 clusters, percentile 85\n",
      "Finished 128 clusters, percentile 90\n",
      "Finished 256 clusters, percentile 75\n",
      "Finished 256 clusters, percentile 80\n",
      "Finished 256 clusters, percentile 85\n",
      "Finished 256 clusters, percentile 90\n"
     ]
    }
   ],
   "source": [
    "# 3d array of labels. dims=(n_clusters, num_percentiles, num_labels)\n",
    "labels_arr = []\n",
    "\n",
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    kmeans_pth = os.path.join(\"./clustering\", \"comb_ae\", \"kmeans{}\".format(n_clusters))\n",
    "    kmeans = pickle.load(open(kmeans_pth, 'rb'))\n",
    "    \n",
    "    labels_arr.append([])\n",
    "\n",
    "    for percentile in perc_arr:\n",
    "        # Find max distance for each cluster based on percentile\n",
    "        clusters_max_dist_arr, new_labels = find_and_remove_outliers_clustering(\n",
    "            kmeans.labels_, embed_tiles_comb_tr, n_clusters, kmeans.cluster_centers_, percentile) \n",
    "\n",
    "        labels_arr[i].append(new_labels)\n",
    "\n",
    "        # Subdivide all tiles based by original slide\n",
    "        subdivide_clusters_by_slide(n_clusters, new_labels, percentile)\n",
    "\n",
    "        # Save max distances for each cluster\n",
    "        max_dist_cluster_pth = os.path.join(\"./clustering\", \"comb_ae\", \"max_dist_outliers\")\n",
    "        if not os.path.exists(max_dist_cluster_pth):\n",
    "            os.makedirs(max_dist_cluster_pth)\n",
    "        np.save(max_dist_cluster_pth+\"/max_dist_outliers{}_{}.npy\".format(percentile, n_clusters), clusters_max_dist_arr)\n",
    "        print('Finished {} clusters, percentile {}'.format(n_clusters, percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c41f698-18e1-4fc2-883d-5ac98d8e915b",
   "metadata": {},
   "source": [
    "Count outlier tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "33e5f02a-6f25-4d7c-b136-1fa71cc76146",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMEANS: 32\n",
      "PERC: 75\n",
      "outliers: 323112\n",
      "tot: 1292425\n",
      "PERC: 80\n",
      "outliers: 258491\n",
      "tot: 1292425\n",
      "PERC: 85\n",
      "outliers: 193876\n",
      "tot: 1292425\n",
      "PERC: 90\n",
      "outliers: 129256\n",
      "tot: 1292425\n",
      "KMEANS: 64\n",
      "PERC: 75\n",
      "outliers: 323114\n",
      "tot: 1292425\n",
      "PERC: 80\n",
      "outliers: 258498\n",
      "tot: 1292425\n",
      "PERC: 85\n",
      "outliers: 193881\n",
      "tot: 1292425\n",
      "PERC: 90\n",
      "outliers: 129267\n",
      "tot: 1292425\n",
      "KMEANS: 128\n",
      "PERC: 75\n",
      "outliers: 323123\n",
      "tot: 1292425\n",
      "PERC: 80\n",
      "outliers: 258512\n",
      "tot: 1292425\n",
      "PERC: 85\n",
      "outliers: 193910\n",
      "tot: 1292425\n",
      "PERC: 90\n",
      "outliers: 129292\n",
      "tot: 1292425\n",
      "KMEANS: 256\n",
      "PERC: 75\n",
      "outliers: 323136\n",
      "tot: 1292425\n",
      "PERC: 80\n",
      "outliers: 258540\n",
      "tot: 1292425\n",
      "PERC: 85\n",
      "outliers: 193941\n",
      "tot: 1292425\n",
      "PERC: 90\n",
      "outliers: 129331\n",
      "tot: 1292425\n"
     ]
    }
   ],
   "source": [
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    print('KMEANS:', n_clusters)\n",
    "    for j, percentile in enumerate(perc_arr):\n",
    "        print('PERC:', percentile)\n",
    "        labels = labels_arr[i][j]\n",
    "        print('outliers:', np.count_nonzero(labels == -1))\n",
    "        print('tot:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "356dff46-eb70-48db-a61f-1005a516e63f",
   "metadata": {},
   "source": [
    "# Validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02d62e11-9fc7-4595-a9ec-47c426ad29ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_arr = [32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "31f9106c-c592-4623-8591-06a3bc1ee782",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_arr = [75, 80, 85, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3e61e690-3a07-4501-a36a-54fd524752d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 32 clusters\n",
      "Finished 32 clusters, percentile 75\n",
      "Finished 32 clusters, percentile 80\n",
      "Finished 32 clusters, percentile 85\n",
      "Finished 32 clusters, percentile 90\n",
      "Doing 64 clusters\n",
      "Finished 64 clusters, percentile 75\n",
      "Finished 64 clusters, percentile 80\n",
      "Finished 64 clusters, percentile 85\n",
      "Finished 64 clusters, percentile 90\n",
      "Doing 128 clusters\n",
      "Finished 128 clusters, percentile 75\n",
      "Finished 128 clusters, percentile 80\n",
      "Finished 128 clusters, percentile 85\n",
      "Finished 128 clusters, percentile 90\n",
      "Doing 256 clusters\n",
      "Finished 256 clusters, percentile 75\n",
      "Finished 256 clusters, percentile 80\n",
      "Finished 256 clusters, percentile 85\n",
      "Finished 256 clusters, percentile 90\n"
     ]
    }
   ],
   "source": [
    "# 3d array of labels. dims=(n_clusters, num_percentiles, num_labels)\n",
    "labels_arr = []\n",
    "\n",
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    print('Doing {} clusters'.format(n_clusters))\n",
    "    \n",
    "    labels_arr.append([])\n",
    "    \n",
    "    # Recover kmeans model\n",
    "    kmeans_pth = os.path.join(\"./clustering\", \"comb_ae\", \"kmeans{}\".format(n_clusters))\n",
    "    kmeans = pickle.load(open(kmeans_pth, 'rb'))\n",
    "    \n",
    "    # Predict labels\n",
    "    labels = kmeans.predict(embed_tiles_comb_val)\n",
    "        \n",
    "    for percentile in perc_arr:\n",
    "        # Recover max regarding a percentile\n",
    "        max_dist_cluster_pth = os.path.join(\n",
    "            \"./clustering\", \"comb_ae\", \"max_dist_outliers\", \"max_dist_outliers{}_{}.npy\".format(percentile, n_clusters))\n",
    "        clusters_max_dist_arr = np.load(max_dist_cluster_pth)\n",
    "\n",
    "        # Apply removal of tiles with distance over max\n",
    "        new_labels = remove_outliers_clustering(clusters_max_dist_arr,\n",
    "            labels, embed_tiles_comb_val, n_clusters, kmeans.cluster_centers_) \n",
    "\n",
    "        labels_arr[i].append(new_labels)\n",
    "        # Subdivide all tiles based by original slide\n",
    "        subdivide_clusters_by_slide(n_clusters, new_labels, percentile, dataset='comb_val')\n",
    "\n",
    "        print('Finished {} clusters, percentile {}'.format(n_clusters, percentile))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "677db7e3-7454-4718-a19f-d5efc8e028ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 CLUSTERS, PERCENTILE 75\n",
      "outliers: 118773\n",
      "tot: 426670\n",
      "32 CLUSTERS, PERCENTILE 80\n",
      "outliers: 96087\n",
      "tot: 426670\n",
      "32 CLUSTERS, PERCENTILE 85\n",
      "outliers: 73079\n",
      "tot: 426670\n",
      "32 CLUSTERS, PERCENTILE 90\n",
      "outliers: 50147\n",
      "tot: 426670\n",
      "64 CLUSTERS, PERCENTILE 75\n",
      "outliers: 116471\n",
      "tot: 426670\n",
      "64 CLUSTERS, PERCENTILE 80\n",
      "outliers: 94358\n",
      "tot: 426670\n",
      "64 CLUSTERS, PERCENTILE 85\n",
      "outliers: 71895\n",
      "tot: 426670\n",
      "64 CLUSTERS, PERCENTILE 90\n",
      "outliers: 49242\n",
      "tot: 426670\n",
      "128 CLUSTERS, PERCENTILE 75\n",
      "outliers: 114528\n",
      "tot: 426670\n",
      "128 CLUSTERS, PERCENTILE 80\n",
      "outliers: 92365\n",
      "tot: 426670\n",
      "128 CLUSTERS, PERCENTILE 85\n",
      "outliers: 70291\n",
      "tot: 426670\n",
      "128 CLUSTERS, PERCENTILE 90\n",
      "outliers: 47850\n",
      "tot: 426670\n",
      "256 CLUSTERS, PERCENTILE 75\n",
      "outliers: 113789\n",
      "tot: 426670\n",
      "256 CLUSTERS, PERCENTILE 80\n",
      "outliers: 91795\n",
      "tot: 426670\n",
      "256 CLUSTERS, PERCENTILE 85\n",
      "outliers: 69915\n",
      "tot: 426670\n",
      "256 CLUSTERS, PERCENTILE 90\n",
      "outliers: 47513\n",
      "tot: 426670\n"
     ]
    }
   ],
   "source": [
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    for j, percentile in enumerate(perc_arr):\n",
    "        labels = labels_arr[i][j]\n",
    "        print('{} CLUSTERS, PERCENTILE {}'.format(n_clusters, percentile))\n",
    "        print('outliers:', np.count_nonzero(labels == -1))\n",
    "        print('tot:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f1e4b8-5cd4-40c0-9a0c-dc887d48a64a",
   "metadata": {},
   "source": [
    "# Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "667e367a-238a-4ff4-8487-ef1c01470f73",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_clusters_arr = [32, 64, 128, 256]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "992b6a78-d738-4620-81c3-63606577d5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "perc_arr = [75, 80, 85, 90]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae9cc8f2-4d92-4f50-bf5f-2c778173572c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing 32 clusters\n",
      "Finished 32 clusters, percentile 75\n",
      "Finished 32 clusters, percentile 80\n",
      "Finished 32 clusters, percentile 85\n",
      "Finished 32 clusters, percentile 90\n",
      "Doing 64 clusters\n",
      "Finished 64 clusters, percentile 75\n",
      "Finished 64 clusters, percentile 80\n",
      "Finished 64 clusters, percentile 85\n",
      "Finished 64 clusters, percentile 90\n",
      "Doing 128 clusters\n",
      "Finished 128 clusters, percentile 75\n",
      "Finished 128 clusters, percentile 80\n",
      "Finished 128 clusters, percentile 85\n",
      "Finished 128 clusters, percentile 90\n",
      "Doing 256 clusters\n",
      "Finished 256 clusters, percentile 75\n",
      "Finished 256 clusters, percentile 80\n",
      "Finished 256 clusters, percentile 85\n",
      "Finished 256 clusters, percentile 90\n"
     ]
    }
   ],
   "source": [
    "# 3d array of labels. dims=(n_clusters, num_percentiles, num_labels)\n",
    "labels_arr = []\n",
    "\n",
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    print('Doing {} clusters'.format(n_clusters))\n",
    "    \n",
    "    # Recover kmeans model\n",
    "    kmeans_pth = os.path.join(\"./clustering\", \"comb_ae\", \"kmeans{}\".format(n_clusters))\n",
    "    kmeans = pickle.load(open(kmeans_pth, 'rb'))\n",
    "    \n",
    "    labels_arr.append([])\n",
    "    \n",
    "    # Predict labels\n",
    "    labels = kmeans.predict(embed_tiles_comb_ts)\n",
    "    \n",
    "    unique, counts = np.unique(labels, return_counts=True)\n",
    "    dict(zip(unique, counts))\n",
    "    \n",
    "    for percentile in perc_arr:\n",
    "        # Recover max regarding a percentile\n",
    "        max_dist_cluster_pth = os.path.join(\n",
    "            \"./clustering\", \"comb_ae\", \"max_dist_outliers\", \"max_dist_outliers{}_{}.npy\".format(percentile, n_clusters))\n",
    "        clusters_max_dist_arr = np.load(max_dist_cluster_pth)\n",
    "\n",
    "        # Apply removal of tiles with distance over max\n",
    "        new_labels = remove_outliers_clustering(clusters_max_dist_arr,\n",
    "            labels, embed_tiles_comb_ts, n_clusters, kmeans.cluster_centers_) \n",
    "\n",
    "        labels_arr[i].append(new_labels)\n",
    "        # Subdivide all tiles based by original slide\n",
    "        subdivide_clusters_by_slide(n_clusters, new_labels, percentile, dataset='comb_ts')\n",
    "\n",
    "        print('Finished {} clusters, percentile {}'.format(n_clusters, percentile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e8869ed-7f1c-4e61-84dc-2ecbc7192514",
   "metadata": {},
   "source": [
    "Count outlier tiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "96638eaa-40b0-4c48-9707-9e50dce3b58d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32 CLUSTERS, PERCENTILE 75\n",
      "outliers: 99155\n",
      "tot: 342323\n",
      "32 CLUSTERS, PERCENTILE 80\n",
      "outliers: 78179\n",
      "tot: 342323\n",
      "32 CLUSTERS, PERCENTILE 85\n",
      "outliers: 57101\n",
      "tot: 342323\n",
      "32 CLUSTERS, PERCENTILE 90\n",
      "outliers: 36601\n",
      "tot: 342323\n",
      "64 CLUSTERS, PERCENTILE 75\n",
      "outliers: 98896\n",
      "tot: 342323\n",
      "64 CLUSTERS, PERCENTILE 80\n",
      "outliers: 78178\n",
      "tot: 342323\n",
      "64 CLUSTERS, PERCENTILE 85\n",
      "outliers: 57433\n",
      "tot: 342323\n",
      "64 CLUSTERS, PERCENTILE 90\n",
      "outliers: 37086\n",
      "tot: 342323\n",
      "128 CLUSTERS, PERCENTILE 75\n",
      "outliers: 102131\n",
      "tot: 342323\n",
      "128 CLUSTERS, PERCENTILE 80\n",
      "outliers: 81105\n",
      "tot: 342323\n",
      "128 CLUSTERS, PERCENTILE 85\n",
      "outliers: 59918\n",
      "tot: 342323\n",
      "128 CLUSTERS, PERCENTILE 90\n",
      "outliers: 38783\n",
      "tot: 342323\n",
      "256 CLUSTERS, PERCENTILE 75\n",
      "outliers: 103606\n",
      "tot: 342323\n",
      "256 CLUSTERS, PERCENTILE 80\n",
      "outliers: 82594\n",
      "tot: 342323\n",
      "256 CLUSTERS, PERCENTILE 85\n",
      "outliers: 61425\n",
      "tot: 342323\n",
      "256 CLUSTERS, PERCENTILE 90\n",
      "outliers: 40166\n",
      "tot: 342323\n"
     ]
    }
   ],
   "source": [
    "for i, n_clusters in enumerate(n_clusters_arr):\n",
    "    for j, percentile in enumerate(perc_arr):\n",
    "        labels = labels_arr[i][j]\n",
    "        print('{} CLUSTERS, PERCENTILE {}'.format(n_clusters, percentile))\n",
    "        print('outliers:', np.count_nonzero(labels == -1))\n",
    "        print('tot:', len(labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3615412-bbe4-4de7-bd78-6a38bf9ac896",
   "metadata": {},
   "source": [
    "Count samples percentage for each cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa7c7d75-5170-48e9-9bc1-800d0e6ccd7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{-1: 6789825.0,\n",
       " 0: 197575.0,\n",
       " 1: 610200.0,\n",
       " 2: 1507300.0,\n",
       " 3: 361275.0,\n",
       " 4: 163525.0,\n",
       " 5: 491450.0,\n",
       " 6: 442275.0,\n",
       " 7: 370200.0,\n",
       " 8: 370250.0,\n",
       " 9: 359900.0,\n",
       " 10: 837550.0,\n",
       " 11: 621225.0,\n",
       " 12: 614750.0,\n",
       " 13: 171825.0,\n",
       " 14: 172250.0,\n",
       " 15: 143025.0,\n",
       " 16: 130425.0,\n",
       " 17: 270550.0,\n",
       " 18: 249975.0,\n",
       " 19: 473825.0,\n",
       " 20: 314400.0,\n",
       " 21: 486350.0,\n",
       " 22: 492700.0,\n",
       " 23: 492800.0,\n",
       " 24: 226400.0,\n",
       " 25: 142575.0,\n",
       " 26: 495725.0,\n",
       " 27: 848975.0,\n",
       " 28: 287200.0,\n",
       " 29: 273100.0,\n",
       " 30: 387975.0,\n",
       " 31: 119750.0,\n",
       " 32: 1115550.0,\n",
       " 33: 895850.0,\n",
       " 34: 505075.0,\n",
       " 35: 484100.0,\n",
       " 36: 1440825.0,\n",
       " 37: 160250.0,\n",
       " 38: 395900.0,\n",
       " 39: 184800.0,\n",
       " 40: 208325.0,\n",
       " 41: 703475.0,\n",
       " 42: 451125.0,\n",
       " 43: 360300.0,\n",
       " 44: 177375.0,\n",
       " 45: 150500.0,\n",
       " 46: 395675.0,\n",
       " 47: 399900.0,\n",
       " 48: 348225.0,\n",
       " 49: 348850.0,\n",
       " 50: 464800.0,\n",
       " 51: 175925.0,\n",
       " 52: 1089025.0,\n",
       " 53: 441775.0,\n",
       " 54: 869825.0,\n",
       " 55: 140100.0,\n",
       " 56: 363350.0,\n",
       " 57: 2200.0,\n",
       " 58: 149325.0,\n",
       " 59: 510450.0,\n",
       " 60: 298175.0,\n",
       " 61: 228075.0,\n",
       " 62: 621150.0,\n",
       " 63: 234900.0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique, counts = np.unique(labels_arr[1], return_counts=True)\n",
    "dict(zip(unique, np.divide(counts*100, len(labels_arr[1]))))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
