{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f81b05cc-2aed-4a89-8c2d-5ee90f0a4cda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from torch.utils import data\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.models as models\n",
    "from torch.autograd import Variable\n",
    "import torchvision.transforms as transforms\n",
    "import time\n",
    "\n",
    "from autoencoder import autoencoder, train, evaluate\n",
    "from dataset import Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4018f730-c1ae-4934-92c4-a8d3f8a51962",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c31ce237-4d99-4b50-aee3-73f876b18227",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model_path = './ae_models/ae/'\n",
    "\n",
    "# EncoderCNN architecture\n",
    "fc_hidden1 = 256\n",
    "embed_dim = 32     # latent dim extracted by 2D CNN\n",
    "dropout_p = 0.2       # dropout probability\n",
    "\n",
    "# training parameters\n",
    "start_epoch = 14\n",
    "epochs = 20     # training epochs\n",
    "batch_size = 8\n",
    "learning_rate = 1e-3\n",
    "log_interval = 1000   # interval for displaying training info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80c058d5-092a-4f45-a5e1-b2e04683a922",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './ae_models/ae/model_epoch14.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-aaf2aaf6c021>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mstart_epoch\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m     \u001b[0mmodel_load_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msave_model_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'model_epoch{}.pth'\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_epoch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m     \u001b[0mautoencoder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_load_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Using\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"GPU\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36mload\u001b[1;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[0;32m    697\u001b[0m         \u001b[0mpickle_load_args\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'encoding'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'utf-8'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    698\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 699\u001b[1;33m     \u001b[1;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    700\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0m_is_zipfile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    701\u001b[0m             \u001b[1;31m# The zipfile reader is going to advance the current file position.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[1;34m(name_or_buffer, mode)\u001b[0m\n\u001b[0;32m    229\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    230\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 231\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    232\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;34m'w'\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\torch\\serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, name, mode)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './ae_models/ae/model_epoch14.pth'"
     ]
    }
   ],
   "source": [
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                #transforms.Lambda(lambda x: x.repeat(3, 1, 1)),  # gray -> GRB 3 channel (lambda function)\n",
    "                                #transforms.Normalize(mean=[0.0, 0.0, 0.0], std=[1.0, 1.0, 1.0])\n",
    "                               ])  # for grayscale images\n",
    "\n",
    "# tiles dataset\n",
    "tiles_dataset = Dataset(dir_path='../WSI/tiles/', transform=transform, dataset='tr')\n",
    "\n",
    "# Data loader \n",
    "train_loader = torch.utils.data.DataLoader(dataset=tiles_dataset, batch_size=batch_size, shuffle=True, drop_last=True)\n",
    "#valid_loader = torch.utils.data.DataLoader(dataset=tiles_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "autoencoder = autoencoder(fc_hidden1=fc_hidden1, drop_p=dropout_p, embed_dim=embed_dim).to(device)\n",
    "    \n",
    "# Recover model                                \n",
    "if start_epoch != 0:\n",
    "    model_load_path = os.path.join(save_model_path, 'model_epoch{}.pth'.format(start_epoch))\n",
    "    autoencoder.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU\")\n",
    "model_params = list(autoencoder.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "# Recover optimizer                                \n",
    "if start_epoch != 0:\n",
    "    optimizer_load_path = os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(start_epoch))\n",
    "    optimizer.load_state_dict(torch.load(optimizer_load_path))\n",
    "    \n",
    "\n",
    "epoch_train_losses = []\n",
    "epoch_test_losses = []\n",
    "\n",
    "# start training\n",
    "for epoch in range(start_epoch, epochs):\n",
    "\n",
    "    # train, test model\n",
    "    X_train, z_train, train_losses = train(log_interval, autoencoder, device, train_loader, optimizer, epoch, save_model_path)\n",
    "    #X_test, y_test, z_test, mu_test, logvar_test, epoch_test_loss = validation(resnet_vae, device, optimizer, valid_loader)\n",
    "\n",
    "    # save results\n",
    "    epoch_train_losses.append(train_losses)\n",
    "    #epoch_test_losses.append(epoch_test_loss)\n",
    "\n",
    "    \n",
    "    # save all train test results\n",
    "    A = np.array(epoch_train_losses)\n",
    "    #C = np.array(epoch_test_losses)\n",
    "    \n",
    "    np.save(os.path.join(save_model_path, 'autoencoder_training_loss.npy'), A)\n",
    "    np.save(os.path.join(save_model_path, 'X_ae_train_epoch{}.npy'.format(epoch + 1)), X_train) #save last batch\n",
    "    np.save(os.path.join(save_model_path, 'z_ae_train_epoch{}.npy'.format(epoch + 1)), z_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8c513654",
   "metadata": {},
   "source": [
    "See loss curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a50fe222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 166494)\n",
      "[[39465.8984375  39385.44140625 39076.1796875  ... 41471.4609375\n",
      "  37312.58984375 36979.515625  ]\n",
      " [40819.234375   37718.46875    37465.67578125 ... 39333.5\n",
      "  39408.71875    36919.8515625 ]\n",
      " [39553.1015625  37407.57421875 34201.50390625 ... 36990.578125\n",
      "  37928.82421875 41303.40625   ]\n",
      " [35861.78125    36098.984375   41587.96875    ... 36376.97265625\n",
      "  38091.4296875  40813.22265625]\n",
      " [36460.19921875 39564.625      36749.99609375 ... 38107.80078125\n",
      "  34141.4375     38893.02734375]\n",
      " [39234.7109375  37108.7578125  38017.7578125  ... 38693.31640625\n",
      "  41565.1875     35545.98046875]]\n"
     ]
    }
   ],
   "source": [
    "ae_loss_train = np.load(save_model_path+'/autoencoder_training_loss.npy')\n",
    "print(ae_loss_train.shape)\n",
    "print(ae_loss_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "bb310025-bea0-499d-905a-0b14e33ca9cf",
   "metadata": {},
   "source": [
    "Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "abdf0bb1-857e-40c1-99f1-d10a37fce6aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n",
      "Eval: [8000/1331953 (1%)]\tLoss: 33068.367188\n",
      "Eval: [16000/1331953 (1%)]\tLoss: 35239.742188\n",
      "Eval: [24000/1331953 (2%)]\tLoss: 35465.242188\n",
      "Eval: [32000/1331953 (2%)]\tLoss: 34728.171875\n",
      "Eval: [40000/1331953 (3%)]\tLoss: 35035.937500\n",
      "Eval: [48000/1331953 (4%)]\tLoss: 32431.562500\n",
      "Eval: [56000/1331953 (4%)]\tLoss: 39313.914062\n",
      "Eval: [64000/1331953 (5%)]\tLoss: 38362.992188\n",
      "Eval: [72000/1331953 (5%)]\tLoss: 35454.273438\n",
      "Eval: [80000/1331953 (6%)]\tLoss: 50810.789062\n",
      "Eval: [88000/1331953 (7%)]\tLoss: 54876.113281\n",
      "Eval: [96000/1331953 (7%)]\tLoss: 37796.687500\n",
      "Eval: [104000/1331953 (8%)]\tLoss: 46583.910156\n",
      "Eval: [112000/1331953 (8%)]\tLoss: 52435.742188\n",
      "Eval: [120000/1331953 (9%)]\tLoss: 31942.667969\n",
      "Eval: [128000/1331953 (10%)]\tLoss: 44556.589844\n",
      "Eval: [136000/1331953 (10%)]\tLoss: 39604.101562\n",
      "Eval: [144000/1331953 (11%)]\tLoss: 41066.601562\n",
      "Eval: [152000/1331953 (11%)]\tLoss: 34181.765625\n",
      "Eval: [160000/1331953 (12%)]\tLoss: 34731.656250\n",
      "Eval: [168000/1331953 (13%)]\tLoss: 40257.625000\n",
      "Eval: [176000/1331953 (13%)]\tLoss: 37145.058594\n",
      "Eval: [184000/1331953 (14%)]\tLoss: 34830.843750\n",
      "Eval: [192000/1331953 (14%)]\tLoss: 38188.562500\n",
      "Eval: [200000/1331953 (15%)]\tLoss: 37480.253906\n",
      "Eval: [208000/1331953 (16%)]\tLoss: 35037.468750\n",
      "Eval: [216000/1331953 (16%)]\tLoss: 37358.296875\n",
      "Eval: [224000/1331953 (17%)]\tLoss: 35660.429688\n",
      "Eval: [232000/1331953 (17%)]\tLoss: 36938.488281\n",
      "Eval: [240000/1331953 (18%)]\tLoss: 38883.585938\n",
      "Eval: [248000/1331953 (19%)]\tLoss: 32276.222656\n",
      "Eval: [256000/1331953 (19%)]\tLoss: 41446.078125\n",
      "Eval: [264000/1331953 (20%)]\tLoss: 40299.484375\n",
      "Eval: [272000/1331953 (20%)]\tLoss: 41095.390625\n",
      "Eval: [280000/1331953 (21%)]\tLoss: 38895.609375\n",
      "Eval: [288000/1331953 (22%)]\tLoss: 36576.382812\n",
      "Eval: [296000/1331953 (22%)]\tLoss: 34397.683594\n",
      "Eval: [304000/1331953 (23%)]\tLoss: 30743.962891\n",
      "Eval: [312000/1331953 (23%)]\tLoss: 40230.613281\n",
      "Eval: [320000/1331953 (24%)]\tLoss: 31584.632812\n",
      "Eval: [328000/1331953 (25%)]\tLoss: 36140.746094\n",
      "Eval: [336000/1331953 (25%)]\tLoss: 35950.687500\n",
      "Eval: [344000/1331953 (26%)]\tLoss: 33372.234375\n",
      "Eval: [352000/1331953 (26%)]\tLoss: 39081.320312\n",
      "Eval: [360000/1331953 (27%)]\tLoss: 33080.492188\n",
      "Eval: [368000/1331953 (28%)]\tLoss: 42976.390625\n",
      "Eval: [376000/1331953 (28%)]\tLoss: 45267.269531\n",
      "Eval: [384000/1331953 (29%)]\tLoss: 47200.214844\n",
      "Eval: [392000/1331953 (29%)]\tLoss: 43979.187500\n",
      "Eval: [400000/1331953 (30%)]\tLoss: 45247.414062\n",
      "Eval: [408000/1331953 (31%)]\tLoss: 33659.851562\n",
      "Eval: [416000/1331953 (31%)]\tLoss: 40356.488281\n",
      "Eval: [424000/1331953 (32%)]\tLoss: 37439.937500\n",
      "Eval: [432000/1331953 (32%)]\tLoss: 35560.882812\n",
      "Eval: [440000/1331953 (33%)]\tLoss: 33953.519531\n",
      "Eval: [448000/1331953 (34%)]\tLoss: 33142.261719\n",
      "Eval: [456000/1331953 (34%)]\tLoss: 35824.960938\n",
      "Eval: [464000/1331953 (35%)]\tLoss: 31268.287109\n",
      "Eval: [472000/1331953 (35%)]\tLoss: 28675.636719\n",
      "Eval: [480000/1331953 (36%)]\tLoss: 31429.466797\n",
      "Eval: [488000/1331953 (37%)]\tLoss: 38915.796875\n",
      "Eval: [496000/1331953 (37%)]\tLoss: 33138.273438\n",
      "Eval: [504000/1331953 (38%)]\tLoss: 30185.773438\n",
      "Eval: [512000/1331953 (38%)]\tLoss: 33647.234375\n",
      "Eval: [520000/1331953 (39%)]\tLoss: 34562.179688\n",
      "Eval: [528000/1331953 (40%)]\tLoss: 43450.882812\n",
      "Eval: [536000/1331953 (40%)]\tLoss: 44409.117188\n",
      "Eval: [544000/1331953 (41%)]\tLoss: 39129.546875\n",
      "Eval: [552000/1331953 (41%)]\tLoss: 45920.687500\n",
      "Eval: [560000/1331953 (42%)]\tLoss: 47125.304688\n",
      "Eval: [568000/1331953 (43%)]\tLoss: 40286.718750\n",
      "Eval: [576000/1331953 (43%)]\tLoss: 35810.632812\n",
      "Eval: [584000/1331953 (44%)]\tLoss: 35307.363281\n",
      "Eval: [592000/1331953 (44%)]\tLoss: 44532.585938\n",
      "Eval: [600000/1331953 (45%)]\tLoss: 47397.414062\n",
      "Eval: [608000/1331953 (46%)]\tLoss: 45813.343750\n",
      "Eval: [616000/1331953 (46%)]\tLoss: 32053.984375\n",
      "Eval: [624000/1331953 (47%)]\tLoss: 33097.351562\n",
      "Eval: [632000/1331953 (47%)]\tLoss: 38397.382812\n",
      "Eval: [640000/1331953 (48%)]\tLoss: 34711.804688\n",
      "Eval: [648000/1331953 (49%)]\tLoss: 40287.855469\n",
      "Eval: [656000/1331953 (49%)]\tLoss: 35879.460938\n",
      "Eval: [664000/1331953 (50%)]\tLoss: 33983.250000\n",
      "Eval: [672000/1331953 (50%)]\tLoss: 36597.917969\n",
      "Eval: [680000/1331953 (51%)]\tLoss: 34993.113281\n",
      "Eval: [688000/1331953 (52%)]\tLoss: 34460.949219\n",
      "Eval: [696000/1331953 (52%)]\tLoss: 32334.058594\n",
      "Eval: [704000/1331953 (53%)]\tLoss: 32031.603516\n",
      "Eval: [712000/1331953 (53%)]\tLoss: 61347.792969\n",
      "Eval: [720000/1331953 (54%)]\tLoss: 37111.898438\n",
      "Eval: [728000/1331953 (55%)]\tLoss: 31095.197266\n",
      "Eval: [736000/1331953 (55%)]\tLoss: 37127.425781\n",
      "Eval: [744000/1331953 (56%)]\tLoss: 33811.574219\n",
      "Eval: [752000/1331953 (56%)]\tLoss: 35998.687500\n",
      "Eval: [760000/1331953 (57%)]\tLoss: 35029.347656\n",
      "Eval: [768000/1331953 (58%)]\tLoss: 36874.203125\n",
      "Eval: [776000/1331953 (58%)]\tLoss: 33597.343750\n",
      "Eval: [784000/1331953 (59%)]\tLoss: 30858.208984\n",
      "Eval: [792000/1331953 (59%)]\tLoss: 30646.019531\n",
      "Eval: [800000/1331953 (60%)]\tLoss: 39958.269531\n",
      "Eval: [808000/1331953 (61%)]\tLoss: 39185.953125\n",
      "Eval: [816000/1331953 (61%)]\tLoss: 41363.585938\n",
      "Eval: [824000/1331953 (62%)]\tLoss: 39712.796875\n",
      "Eval: [832000/1331953 (62%)]\tLoss: 36153.390625\n",
      "Eval: [840000/1331953 (63%)]\tLoss: 31545.560547\n",
      "Eval: [848000/1331953 (64%)]\tLoss: 33365.734375\n",
      "Eval: [856000/1331953 (64%)]\tLoss: 33963.914062\n",
      "Eval: [864000/1331953 (65%)]\tLoss: 33098.300781\n",
      "Eval: [872000/1331953 (65%)]\tLoss: 35021.183594\n",
      "Eval: [880000/1331953 (66%)]\tLoss: 39937.664062\n",
      "Eval: [888000/1331953 (67%)]\tLoss: 36919.671875\n",
      "Eval: [896000/1331953 (67%)]\tLoss: 32021.414062\n",
      "Eval: [904000/1331953 (68%)]\tLoss: 52767.289062\n",
      "Eval: [912000/1331953 (68%)]\tLoss: 47396.933594\n",
      "Eval: [920000/1331953 (69%)]\tLoss: 47503.515625\n",
      "Eval: [928000/1331953 (70%)]\tLoss: 48586.210938\n",
      "Eval: [936000/1331953 (70%)]\tLoss: 47010.468750\n",
      "Eval: [944000/1331953 (71%)]\tLoss: 50084.789062\n",
      "Eval: [952000/1331953 (71%)]\tLoss: 33613.500000\n",
      "Eval: [960000/1331953 (72%)]\tLoss: 34571.472656\n",
      "Eval: [968000/1331953 (73%)]\tLoss: 37911.773438\n",
      "Eval: [976000/1331953 (73%)]\tLoss: 33956.605469\n",
      "Eval: [984000/1331953 (74%)]\tLoss: 40863.765625\n",
      "Eval: [992000/1331953 (74%)]\tLoss: 34955.914062\n",
      "Eval: [1000000/1331953 (75%)]\tLoss: 35165.976562\n",
      "Eval: [1008000/1331953 (76%)]\tLoss: 54741.945312\n",
      "Eval: [1016000/1331953 (76%)]\tLoss: 44013.109375\n",
      "Eval: [1024000/1331953 (77%)]\tLoss: 49000.281250\n",
      "Eval: [1032000/1331953 (77%)]\tLoss: 42925.988281\n",
      "Eval: [1040000/1331953 (78%)]\tLoss: 48310.054688\n",
      "Eval: [1048000/1331953 (79%)]\tLoss: 42639.394531\n",
      "Eval: [1056000/1331953 (79%)]\tLoss: 41020.710938\n",
      "Eval: [1064000/1331953 (80%)]\tLoss: 47000.734375\n",
      "Eval: [1072000/1331953 (80%)]\tLoss: 44527.437500\n",
      "Eval: [1080000/1331953 (81%)]\tLoss: 45233.906250\n",
      "Eval: [1088000/1331953 (82%)]\tLoss: 32283.957031\n",
      "Eval: [1096000/1331953 (82%)]\tLoss: 38117.746094\n",
      "Eval: [1104000/1331953 (83%)]\tLoss: 31440.072266\n",
      "Eval: [1112000/1331953 (83%)]\tLoss: 40047.117188\n",
      "Eval: [1120000/1331953 (84%)]\tLoss: 31778.878906\n",
      "Eval: [1128000/1331953 (85%)]\tLoss: 34047.960938\n",
      "Eval: [1136000/1331953 (85%)]\tLoss: 31610.855469\n",
      "Eval: [1144000/1331953 (86%)]\tLoss: 31789.060547\n",
      "Eval: [1152000/1331953 (86%)]\tLoss: 31184.078125\n",
      "Eval: [1160000/1331953 (87%)]\tLoss: 33263.277344\n",
      "Eval: [1168000/1331953 (88%)]\tLoss: 48504.871094\n",
      "Eval: [1176000/1331953 (88%)]\tLoss: 48756.601562\n",
      "Eval: [1184000/1331953 (89%)]\tLoss: 50579.988281\n",
      "Eval: [1192000/1331953 (89%)]\tLoss: 48062.355469\n",
      "Eval: [1200000/1331953 (90%)]\tLoss: 42727.757812\n",
      "Eval: [1208000/1331953 (91%)]\tLoss: 35766.218750\n",
      "Eval: [1216000/1331953 (91%)]\tLoss: 48355.992188\n",
      "Eval: [1224000/1331953 (92%)]\tLoss: 45841.601562\n",
      "Eval: [1232000/1331953 (92%)]\tLoss: 43121.726562\n",
      "Eval: [1240000/1331953 (93%)]\tLoss: 42974.421875\n",
      "Eval: [1248000/1331953 (94%)]\tLoss: 40637.429688\n",
      "Eval: [1256000/1331953 (94%)]\tLoss: 44833.878906\n",
      "Eval: [1264000/1331953 (95%)]\tLoss: 43610.398438\n",
      "Eval: [1272000/1331953 (95%)]\tLoss: 40256.867188\n",
      "Eval: [1280000/1331953 (96%)]\tLoss: 34449.074219\n",
      "Eval: [1288000/1331953 (97%)]\tLoss: 39048.515625\n",
      "Eval: [1296000/1331953 (97%)]\tLoss: 35255.484375\n",
      "Eval: [1304000/1331953 (98%)]\tLoss: 30911.839844\n",
      "Eval: [1312000/1331953 (99%)]\tLoss: 42949.144531\n",
      "Eval: [1320000/1331953 (99%)]\tLoss: 32317.929688\n",
      "Eval: [1328000/1331953 (100%)]\tLoss: 36273.273438\n",
      "\n",
      "Test set (1331953 samples): Average loss: 4838.7983\n",
      "\n",
      "eval time:  2207.40706611\n"
     ]
    }
   ],
   "source": [
    "recover_epoch = 20\n",
    "\n",
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               ])\n",
    "\n",
    "# tiles dataset\n",
    "tiles_dataset = Dataset(dir_path='../WSI/tiles/', transform=transform, datset='tr')\n",
    "\n",
    "# Data loader \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=tiles_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "autoencoder = autoencoder(fc_hidden1=fc_hidden1, drop_p=dropout_p, embed_dim=embed_dim).to(device)\n",
    "    \n",
    "# Recover model                                \n",
    "model_load_path = os.path.join(save_model_path, 'model_epoch{}.pth'.format(recover_epoch))\n",
    "autoencoder.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU\")\n",
    "model_params = list(autoencoder.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "\n",
    "# Recover optimizer                                \n",
    "optimizer_load_path = os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(recover_epoch))\n",
    "optimizer.load_state_dict(torch.load(optimizer_load_path))\n",
    "    \n",
    "\n",
    "# Evaluate\n",
    "\n",
    "X_test, z_test, X_reconst_test, epoch_test_loss = evaluate(log_interval, autoencoder, device, optimizer, valid_loader)\n",
    "\n",
    "        \n",
    "np.save(os.path.join(save_model_path, 'AE_test_loss.npy'), epoch_test_loss)\n",
    "np.save(os.path.join(save_model_path, 'X_ae_test_epoch{}.npy'.format(recover_epoch)), X_test)\n",
    "np.save(os.path.join(save_model_path, 'z_ae_test_epoch{}.npy'.format(recover_epoch)), z_test)\n",
    "np.save(os.path.join(save_model_path, 'X_reconst_test_epoch{}.npy'.format(recover_epoch)), X_reconst_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a6b830-827e-42bb-bf16-3d29baeec5c6",
   "metadata": {},
   "source": [
    "# Internal Test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bcc526b7-b7c6-476f-ad13-fd6b8f443cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n",
      "Eval: [8000/207736 (4%)]\tLoss: 35052.511719\n",
      "Eval: [16000/207736 (8%)]\tLoss: 43780.007812\n",
      "Eval: [24000/207736 (12%)]\tLoss: 37405.625000\n",
      "Eval: [32000/207736 (15%)]\tLoss: 36209.277344\n",
      "Eval: [40000/207736 (19%)]\tLoss: 38906.773438\n",
      "Eval: [48000/207736 (23%)]\tLoss: 35476.375000\n",
      "Eval: [56000/207736 (27%)]\tLoss: 37232.390625\n",
      "Eval: [64000/207736 (31%)]\tLoss: 58670.800781\n",
      "Eval: [72000/207736 (35%)]\tLoss: 34106.660156\n",
      "Eval: [80000/207736 (39%)]\tLoss: 33266.226562\n",
      "Eval: [88000/207736 (42%)]\tLoss: 34276.140625\n",
      "Eval: [96000/207736 (46%)]\tLoss: 33910.109375\n",
      "Eval: [104000/207736 (50%)]\tLoss: 37844.257812\n",
      "Eval: [112000/207736 (54%)]\tLoss: 32579.839844\n",
      "Eval: [120000/207736 (58%)]\tLoss: 32866.039062\n",
      "Eval: [128000/207736 (62%)]\tLoss: 34668.191406\n",
      "Eval: [136000/207736 (65%)]\tLoss: 32415.375000\n",
      "Eval: [144000/207736 (69%)]\tLoss: 40883.664062\n",
      "Eval: [152000/207736 (73%)]\tLoss: 30642.175781\n",
      "Eval: [160000/207736 (77%)]\tLoss: 31429.900391\n",
      "Eval: [168000/207736 (81%)]\tLoss: 35718.027344\n",
      "Eval: [176000/207736 (85%)]\tLoss: 41075.148438\n",
      "Eval: [184000/207736 (89%)]\tLoss: 30842.429688\n",
      "Eval: [192000/207736 (92%)]\tLoss: 35791.468750\n",
      "Eval: [200000/207736 (96%)]\tLoss: 37061.996094\n"
     ]
    },
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 9.51 GiB for an array with shape (207736, 3, 64, 64) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-77e425bd0162>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;31m# Evaluate\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mz_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_test_loss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_interval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautoencoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalid_loader\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-7-dc412f77a61f>\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(log_interval, model, device, optimizer, test_loader)\u001b[0m\n\u001b[0;32m     36\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[1;33m/=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_loader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[0mall_z\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_z\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 38\u001b[1;33m     \u001b[0mall_X_reconst\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_X_reconst\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     39\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;31m# show information\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mstack\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\PythonGPU\\lib\\site-packages\\numpy\\core\\shape_base.py\u001b[0m in \u001b[0;36mstack\u001b[1;34m(arrays, axis, out)\u001b[0m\n\u001b[0;32m    432\u001b[0m     \u001b[0msl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mslice\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0maxis\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    433\u001b[0m     \u001b[0mexpanded_arrays\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0msl\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0marr\u001b[0m \u001b[1;32min\u001b[0m \u001b[0marrays\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 434\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_nx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mexpanded_arrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    435\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mconcatenate\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 9.51 GiB for an array with shape (207736, 3, 64, 64) and data type float32"
     ]
    }
   ],
   "source": [
    "recover_epoch = 20\n",
    "\n",
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                               ])\n",
    "\n",
    "# tiles dataset\n",
    "tiles_dataset = Dataset(dir_path='../WSI/tiles/', transform=transform, dataset='ts')\n",
    "\n",
    "# Data loader \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=tiles_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "autoencoder = autoencoder(fc_hidden1=fc_hidden1, drop_p=dropout_p, embed_dim=embed_dim).to(device)\n",
    "    \n",
    "# Recover model                                \n",
    "model_load_path = os.path.join(save_model_path, 'model_epoch{}.pth'.format(recover_epoch))\n",
    "autoencoder.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU\")\n",
    "model_params = list(autoencoder.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "\n",
    "# Recover optimizer                                \n",
    "optimizer_load_path = os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(recover_epoch))\n",
    "optimizer.load_state_dict(torch.load(optimizer_load_path))\n",
    "    \n",
    "\n",
    "# Evaluate\n",
    "\n",
    "X_test, z_test, X_reconst_test, epoch_test_loss = evaluate(log_interval, autoencoder, device, optimizer, valid_loader)\n",
    "\n",
    "    \n",
    "        \n",
    "np.save(os.path.join(save_model_path, 'AE_internal_test_loss.npy'), epoch_test_loss)\n",
    "np.save(os.path.join(save_model_path, 'X_ae_internal_test_epoch{}.npy'.format(recover_epoch)), X_test)\n",
    "np.save(os.path.join(save_model_path, 'z_ae_internal_test_epoch{}.npy'.format(recover_epoch)), z_test)\n",
    "np.save(os.path.join(save_model_path, 'X_reconst_internal_test_epoch{}.npy'.format(recover_epoch)), X_reconst_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72acb1d3-ead2-40b6-8cf5-21cf7676b0b7",
   "metadata": {},
   "source": [
    "# External Test Set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a25d3d75-a850-40b0-9dc2-579b2b464ff1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using 1 GPU\n",
      "Eval: [8000/584729 (1%)]\tLoss: 37477.195312\n",
      "Eval: [16000/584729 (3%)]\tLoss: 38827.632812\n",
      "Eval: [24000/584729 (4%)]\tLoss: 36108.937500\n",
      "Eval: [32000/584729 (5%)]\tLoss: 35325.718750\n",
      "Eval: [40000/584729 (7%)]\tLoss: 53975.320312\n",
      "Eval: [48000/584729 (8%)]\tLoss: 69858.546875\n",
      "Eval: [56000/584729 (10%)]\tLoss: 39068.500000\n",
      "Eval: [64000/584729 (11%)]\tLoss: 37333.078125\n",
      "Eval: [72000/584729 (12%)]\tLoss: 39311.226562\n",
      "Eval: [80000/584729 (14%)]\tLoss: 44708.375000\n",
      "Eval: [88000/584729 (15%)]\tLoss: 42726.285156\n",
      "Eval: [96000/584729 (16%)]\tLoss: 36850.140625\n",
      "Eval: [104000/584729 (18%)]\tLoss: 41644.101562\n",
      "Eval: [112000/584729 (19%)]\tLoss: 38705.960938\n",
      "Eval: [120000/584729 (21%)]\tLoss: 37279.312500\n",
      "Eval: [128000/584729 (22%)]\tLoss: 51444.152344\n",
      "Eval: [136000/584729 (23%)]\tLoss: 42443.140625\n",
      "Eval: [144000/584729 (25%)]\tLoss: 42550.613281\n",
      "Eval: [152000/584729 (26%)]\tLoss: 43150.886719\n",
      "Eval: [160000/584729 (27%)]\tLoss: 42368.843750\n",
      "Eval: [168000/584729 (29%)]\tLoss: 45217.488281\n",
      "Eval: [176000/584729 (30%)]\tLoss: 46049.003906\n",
      "Eval: [184000/584729 (31%)]\tLoss: 37281.640625\n",
      "Eval: [192000/584729 (33%)]\tLoss: 35238.546875\n",
      "Eval: [200000/584729 (34%)]\tLoss: 38522.343750\n",
      "Eval: [208000/584729 (36%)]\tLoss: 37176.195312\n",
      "Eval: [216000/584729 (37%)]\tLoss: 43260.265625\n",
      "Eval: [224000/584729 (38%)]\tLoss: 43197.988281\n",
      "Eval: [232000/584729 (40%)]\tLoss: 38731.964844\n",
      "Eval: [240000/584729 (41%)]\tLoss: 37415.882812\n",
      "Eval: [248000/584729 (42%)]\tLoss: 38250.929688\n",
      "Eval: [256000/584729 (44%)]\tLoss: 51076.875000\n",
      "Eval: [264000/584729 (45%)]\tLoss: 59985.902344\n",
      "Eval: [272000/584729 (47%)]\tLoss: 48864.488281\n",
      "Eval: [280000/584729 (48%)]\tLoss: 56046.449219\n",
      "Eval: [288000/584729 (49%)]\tLoss: 45093.042969\n",
      "Eval: [296000/584729 (51%)]\tLoss: 44000.656250\n",
      "Eval: [304000/584729 (52%)]\tLoss: 42889.085938\n",
      "Eval: [312000/584729 (53%)]\tLoss: 47753.031250\n",
      "Eval: [320000/584729 (55%)]\tLoss: 45913.484375\n",
      "Eval: [328000/584729 (56%)]\tLoss: 41929.710938\n",
      "Eval: [336000/584729 (57%)]\tLoss: 38789.390625\n",
      "Eval: [344000/584729 (59%)]\tLoss: 44668.230469\n",
      "Eval: [352000/584729 (60%)]\tLoss: 46379.578125\n",
      "Eval: [360000/584729 (62%)]\tLoss: 44744.656250\n",
      "Eval: [368000/584729 (63%)]\tLoss: 44905.273438\n",
      "Eval: [376000/584729 (64%)]\tLoss: 38811.628906\n",
      "Eval: [384000/584729 (66%)]\tLoss: 37310.132812\n",
      "Eval: [392000/584729 (67%)]\tLoss: 38461.773438\n",
      "Eval: [400000/584729 (68%)]\tLoss: 39372.968750\n",
      "Eval: [408000/584729 (70%)]\tLoss: 45772.304688\n",
      "Eval: [416000/584729 (71%)]\tLoss: 48066.136719\n",
      "Eval: [424000/584729 (73%)]\tLoss: 45356.632812\n",
      "Eval: [432000/584729 (74%)]\tLoss: 47761.343750\n",
      "Eval: [440000/584729 (75%)]\tLoss: 44633.203125\n",
      "Eval: [448000/584729 (77%)]\tLoss: 42394.648438\n",
      "Eval: [456000/584729 (78%)]\tLoss: 43176.492188\n",
      "Eval: [464000/584729 (79%)]\tLoss: 43219.242188\n",
      "Eval: [472000/584729 (81%)]\tLoss: 47929.195312\n",
      "Eval: [480000/584729 (82%)]\tLoss: 43719.996094\n",
      "Eval: [488000/584729 (83%)]\tLoss: 37415.796875\n",
      "Eval: [496000/584729 (85%)]\tLoss: 36972.351562\n",
      "Eval: [504000/584729 (86%)]\tLoss: 32791.191406\n",
      "Eval: [512000/584729 (88%)]\tLoss: 46684.765625\n",
      "Eval: [520000/584729 (89%)]\tLoss: 34907.167969\n",
      "Eval: [528000/584729 (90%)]\tLoss: 43461.101562\n",
      "Eval: [536000/584729 (92%)]\tLoss: 42367.679688\n",
      "Eval: [544000/584729 (93%)]\tLoss: 36475.378906\n",
      "Eval: [552000/584729 (94%)]\tLoss: 40400.343750\n",
      "Eval: [560000/584729 (96%)]\tLoss: 36526.789062\n",
      "Eval: [568000/584729 (97%)]\tLoss: 42544.613281\n",
      "Eval: [576000/584729 (99%)]\tLoss: 41141.949219\n",
      "Eval: [584000/584729 (100%)]\tLoss: 43532.671875\n",
      "\n",
      "Test set (584729 samples): Average loss: 5385.8684\n",
      "\n",
      "eval time:  2484.08542967\n"
     ]
    }
   ],
   "source": [
    "recover_epoch = 20\n",
    "\n",
    "# Detect devices\n",
    "use_cuda = torch.cuda.is_available()                   # check if GPU exists\n",
    "device = torch.device(\"cuda\" if use_cuda else \"cpu\")   # use CPU or GPU\n",
    "\n",
    "# Data loading parameters\n",
    "params = {'batch_size': batch_size, 'shuffle': True, 'num_workers': 4, 'pin_memory': True} if use_cuda else {}\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                # Normalize to have tr dataset mean and std (params calculated in norm_params.ipynb\n",
    "                                #transforms.Normalize(mean=[-0.2792, -0.2173, -0.0899], std=[1.2762, 1.2154, 1.0878], inplace=True)\n",
    "                               ])\n",
    "\n",
    "# tiles dataset\n",
    "tiles_dataset = Dataset(dir_path='../WSI/tiles/', transform=transform, dataset='ext')\n",
    "\n",
    "# Data loader \n",
    "valid_loader = torch.utils.data.DataLoader(dataset=tiles_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Create model\n",
    "autoencoder = autoencoder(fc_hidden1=fc_hidden1, drop_p=dropout_p, embed_dim=embed_dim).to(device)\n",
    "    \n",
    "# Recover model                                \n",
    "model_load_path = os.path.join(save_model_path, 'model_epoch{}.pth'.format(recover_epoch))\n",
    "autoencoder.load_state_dict(torch.load(model_load_path))\n",
    "\n",
    "print(\"Using\", torch.cuda.device_count(), \"GPU\")\n",
    "model_params = list(autoencoder.parameters())\n",
    "optimizer = torch.optim.Adam(model_params, lr=learning_rate)\n",
    "\n",
    "# Recover optimizer                                \n",
    "optimizer_load_path = os.path.join(save_model_path, 'optimizer_epoch{}.pth'.format(recover_epoch))\n",
    "optimizer.load_state_dict(torch.load(optimizer_load_path))\n",
    "    \n",
    "\n",
    "# Evaluate\n",
    "X_test, z_test, X_reconst_test, epoch_test_loss = evaluate(log_interval, autoencoder, device, optimizer, valid_loader)\n",
    "\n",
    "        \n",
    "np.save(os.path.join(save_model_path, 'AE_ext_test_loss.npy'), epoch_test_loss)\n",
    "np.save(os.path.join(save_model_path, 'X_ae_ext_test_epoch{}.npy'.format(recover_epoch)), X_test)\n",
    "np.save(os.path.join(save_model_path, 'z_ae_ext_test_epoch{}.npy'.format(recover_epoch)), z_test)\n",
    "#np.save(os.path.join(save_model_path, 'X_reconst_ext_test_epoch{}.npy'.format(recover_epoch)), X_reconst_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pdl1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "vscode": {
   "interpreter": {
    "hash": "994350ee2423e6504ff55d05744e896480bca47f12344c18a8c4a4655e3d73cc"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
